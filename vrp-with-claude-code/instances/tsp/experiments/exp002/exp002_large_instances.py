#!/usr/bin/env python3
"""
Large TSP instance experiments with route visualization
Tests 30, 50, 100 node instances with OR-Tools and MIP solvers
"""

import sys
import os
import time
import json
import mlflow
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib

sys.path.append('../src')
sys.path.append('../../../src')
from tsp_utils import TSPDataExtractor
from tsp_ortools import solve_tsp_with_ortools
from tsp_mip import solve_tsp_with_mip
from tsp_visualization import visualize_tsp_route, create_route_comparison_plot


def main():
    print("ğŸš€ å¤§è¦æ¨¡TSPå®Ÿé¨“ã‚’Databricks MLflowã«è¨˜éŒ²ã—ã¾ã™...")
    print("å®Ÿé¨“å¯¾è±¡: 30, 50ãƒãƒ¼ãƒ‰ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
    
    # Databricks MLflowè¨­å®š
    mlflow.set_tracking_uri("databricks")
    mlflow.set_experiment("/Shared/data_science/z_ogai/tsp-experiments")
    
    # 1. å¤§è¦æ¨¡TSPã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    print("\n1. å¤§è¦æ¨¡TSPã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆä¸­...")
    vrp_file = "../../tai75a/data/tai75a.vrp"
    extractor = TSPDataExtractor(vrp_file)
    
    tsp_sizes = [30, 50]
    tsp_instances = {}
    
    for size in tsp_sizes:
        print(f"  TSP{size}ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆä¸­...")
        tsp_data = extractor.extract_tsp_subset(size, include_depot=True)
        tsp_instances[f"tsp{size}"] = tsp_data
        print(f"    TSP{size}: {tsp_data['dimension']} nodes")
        print(f"    Distance matrix shape: {tsp_data['distance_matrix'].shape}")
    
    # 2. OR-Toolsã§è§£ã
    print("\n2. OR-Toolsã§å¤§è¦æ¨¡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£ã„ã¦ã„ã¾ã™...")
    ortools_results = {}
    
    for name, tsp_data in tsp_instances.items():
        print(f"  {name}ã‚’OR-Toolsã§è§£ã„ã¦ã„ã¾ã™...")
        
        # å¤§ããªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ã¯é•·ã‚ã®æ™‚é–“åˆ¶é™ã‚’è¨­å®š
        size = tsp_data['dimension']
        if size <= 30:
            time_limit = 120
        elif size <= 50:
            time_limit = 300  # 5åˆ†
        else:
            time_limit = 600  # 10åˆ†
            
        print(f"    Time limit: {time_limit}ç§’")
        
        start_time = time.time()
        result = solve_tsp_with_ortools(tsp_data, time_limit=time_limit)
        elapsed_time = time.time() - start_time
        
        ortools_results[name] = result
        
        cost = result.get('solution_cost', 'N/A')
        solve_time = result.get('solve_time_seconds', elapsed_time)
        print(f"    ã‚³ã‚¹ãƒˆ: {cost}, æ™‚é–“: {solve_time:.2f}ç§’")
    
    # 3. MIPã§è§£ã
    print("\n3. MIPã§å¤§è¦æ¨¡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è§£ã„ã¦ã„ã¾ã™...")
    mip_results = {}
    
    for name, tsp_data in tsp_instances.items():
        print(f"  {name}ã‚’MIPã§è§£ã„ã¦ã„ã¾ã™...")
        
        # å¤§ããªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ã¯é•·ã‚ã®æ™‚é–“åˆ¶é™ã‚’è¨­å®š
        size = tsp_data['dimension']
        if size <= 30:
            time_limit = 120
        elif size <= 50:
            time_limit = 300  # 5åˆ†
        else:
            time_limit = 600  # 10åˆ†
            
        print(f"    Time limit: {time_limit}ç§’")
        
        start_time = time.time()
        result = solve_tsp_with_mip(tsp_data, time_limit=time_limit)
        elapsed_time = time.time() - start_time
        
        mip_results[name] = result
        
        cost = result.get('solution_cost', 'N/A')
        solve_time = result.get('solve_time_seconds', elapsed_time)
        print(f"    ã‚³ã‚¹ãƒˆ: {cost}, æ™‚é–“: {solve_time:.2f}ç§’")
    
    # 4. æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    print("\n4. æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...")
    comparison_data = []
    
    for name in tsp_instances.keys():
        ortools_cost = ortools_results[name].get('solution_cost', float('inf'))
        mip_cost = mip_results[name].get('solution_cost', float('inf'))
        ortools_time = ortools_results[name].get('solve_time_seconds', 0)
        mip_time = mip_results[name].get('solve_time_seconds', 0)
        
        if ortools_cost == float('inf') and mip_cost == float('inf'):
            winner = "None"
        elif ortools_cost == float('inf'):
            winner = "MIP"
        elif mip_cost == float('inf'):
            winner = "OR-Tools"
        elif ortools_cost < mip_cost:
            winner = "OR-Tools"
        elif mip_cost < ortools_cost:
            winner = "MIP"
        else:
            winner = "Tie"
        
        comparison_data.append({
            'instance': name,
            'size': int(name.replace('tsp', '')),
            'ortools_cost': ortools_cost,
            'mip_cost': mip_cost,
            'ortools_time': ortools_time,
            'mip_time': mip_time,
            'winner': winner
        })
    
    # 5. ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–ã‚’ä½œæˆ
    print("\n5. ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
    
    visualization_files = []
    
    for name, tsp_data in tsp_instances.items():
        ortools_result = ortools_results[name]
        mip_result = mip_results[name]
        
        # å„ã‚½ãƒ«ãƒãƒ¼ã®çµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        ortools_tour = ortools_result.get('tour', [])
        mip_tour = mip_result.get('tour', [])
        ortools_cost = ortools_result.get('solution_cost', 0)
        mip_cost = mip_result.get('solution_cost', 0)
        
        if ortools_tour or mip_tour:
            # æ¯”è¼ƒå¯è¦–åŒ–ã‚’ä½œæˆ
            comparison_file = f"{name}_route_comparison.png"
            create_route_comparison_plot(
                tsp_data, 
                ortools_tour, 
                mip_tour,
                ortools_cost,
                mip_cost,
                comparison_file
            )
            visualization_files.append(comparison_file)
            print(f"    {comparison_file} ã‚’ä½œæˆã—ã¾ã—ãŸ")
        
        # å€‹åˆ¥ã®ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–
        if ortools_tour:
            ortools_file = f"{name}_ortools_route.png"
            visualize_tsp_route(
                tsp_data,
                ortools_tour,
                f"OR-Tools Solution - {name.upper()} (Cost: {ortools_cost:.1f})",
                ortools_file
            )
            visualization_files.append(ortools_file)
        
        if mip_tour:
            mip_file = f"{name}_mip_route.png"
            visualize_tsp_route(
                tsp_data,
                mip_tour,
                f"MIP Solution - {name.upper()} (Cost: {mip_cost:.1f})",
                mip_file
            )
            visualization_files.append(mip_file)
    
    # 6. çµ±è¨ˆå¯è¦–åŒ–ã‚’ä½œæˆ
    print("6. çµ±è¨ˆå¯è¦–åŒ–ã‚’ä½œæˆä¸­...")
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    sizes = [data['size'] for data in comparison_data]
    ortools_costs = [data['ortools_cost'] for data in comparison_data]
    mip_costs = [data['mip_cost'] for data in comparison_data]
    ortools_times = [data['ortools_time'] for data in comparison_data]
    mip_times = [data['mip_time'] for data in comparison_data]
    
    # ã‚³ã‚¹ãƒˆæ¯”è¼ƒ
    ax1.plot(sizes, ortools_costs, 'o-', label='OR-Tools', color='blue', linewidth=2, markersize=8)
    ax1.plot(sizes, mip_costs, 's-', label='MIP', color='red', linewidth=2, markersize=8)
    ax1.set_xlabel('TSP Instance Size')
    ax1.set_ylabel('Solution Cost')
    ax1.set_title('Solution Quality Comparison (Large Instances)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_yscale('log')  # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§è¦‹ã‚„ã™ã
    
    # æ™‚é–“æ¯”è¼ƒ
    ax2.plot(sizes, ortools_times, 'o-', label='OR-Tools', color='blue', linewidth=2, markersize=8)
    ax2.plot(sizes, mip_times, 's-', label='MIP', color='red', linewidth=2, markersize=8)
    ax2.set_xlabel('TSP Instance Size')
    ax2.set_ylabel('Solve Time (seconds)')
    ax2.set_title('Computation Time Comparison (Large Instances)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_yscale('log')  # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§è¦‹ã‚„ã™ã
    
    # æ£’ã‚°ãƒ©ãƒ• - ã‚³ã‚¹ãƒˆ
    x = np.arange(len(sizes))
    width = 0.35
    ax3.bar(x - width/2, ortools_costs, width, label='OR-Tools', color='blue', alpha=0.7)
    ax3.bar(x + width/2, mip_costs, width, label='MIP', color='red', alpha=0.7)
    ax3.set_xlabel('TSP Instance Size')
    ax3.set_ylabel('Solution Cost')
    ax3.set_title('Solution Cost Comparison (Large Instances)')
    ax3.set_xticks(x)
    ax3.set_xticklabels([f'TSP{s}' for s in sizes])
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # æ£’ã‚°ãƒ©ãƒ• - æ™‚é–“
    ax4.bar(x - width/2, ortools_times, width, label='OR-Tools', color='blue', alpha=0.7)
    ax4.bar(x + width/2, mip_times, width, label='MIP', color='red', alpha=0.7)
    ax4.set_xlabel('TSP Instance Size')
    ax4.set_ylabel('Solve Time (seconds)')
    ax4.set_title('Computation Time Comparison (Large Instances)')
    ax4.set_xticks(x)
    ax4.set_xticklabels([f'TSP{s}' for s in sizes])
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    stats_plot_file = 'large_tsp_comparison_stats.png'
    plt.savefig(stats_plot_file, dpi=100, bbox_inches='tight', facecolor='white')
    plt.close()
    visualization_files.append(stats_plot_file)
    
    # 7. Databricks MLflowã«è¨˜éŒ²
    print("\n7. Databricks MLflowã«è¨˜éŒ²ä¸­...")
    
    # OR-Toolsçµæœã‚’è¨˜éŒ²
    for name, result in ortools_results.items():
        with mlflow.start_run(run_name=f"ortools_{name}_large"):
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°
            mlflow.log_param("solver_type", "OR-Tools")
            mlflow.log_param("instance_name", name)
            mlflow.log_param("instance_size", result['instance_info']['dimension'])
            mlflow.log_param("experiment_type", "large_instances")
            
            if 'model_params' in result:
                for param, value in result['model_params'].items():
                    mlflow.log_param(param, value)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°
            if 'solution_cost' in result:
                mlflow.log_metric("solution_cost", result['solution_cost'])
            
            if 'solve_time_seconds' in result:
                mlflow.log_metric("solve_time_seconds", result['solve_time_seconds'])
            
            if 'is_optimal' in result:
                mlflow.log_metric("is_optimal", 1 if result['is_optimal'] else 0)
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²
            result_file = f"{name}_ortools_large_result.json"
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2, default=str)
            mlflow.log_artifact(result_file)
            os.remove(result_file)
            
            # ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²
            ortools_route_file = f"{name}_ortools_route.png"
            if ortools_route_file in visualization_files:
                mlflow.log_artifact(ortools_route_file)
    
    print("  OR-Toolsçµæœã‚’Databricks MLflowã«è¨˜éŒ²ã—ã¾ã—ãŸ")
    
    # MIPçµæœã‚’è¨˜éŒ²
    for name, result in mip_results.items():
        with mlflow.start_run(run_name=f"mip_{name}_large"):
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°
            mlflow.log_param("solver_type", "MIP")
            mlflow.log_param("instance_name", name)
            mlflow.log_param("instance_size", result['instance_info']['dimension'])
            mlflow.log_param("experiment_type", "large_instances")
            
            if 'model_params' in result:
                for param, value in result['model_params'].items():
                    mlflow.log_param(param, value)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ­ã‚°
            if 'solution_cost' in result:
                mlflow.log_metric("solution_cost", result['solution_cost'])
            
            if 'solve_time_seconds' in result:
                mlflow.log_metric("solve_time_seconds", result['solve_time_seconds'])
            
            if 'is_optimal' in result:
                mlflow.log_metric("is_optimal", 1 if result['is_optimal'] else 0)
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²
            result_file = f"{name}_mip_large_result.json"
            with open(result_file, 'w') as f:
                json.dump(result, f, indent=2, default=str)
            mlflow.log_artifact(result_file)
            os.remove(result_file)
            
            # ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²
            mip_route_file = f"{name}_mip_route.png"
            if mip_route_file in visualization_files:
                mlflow.log_artifact(mip_route_file)
    
    print("  MIPçµæœã‚’Databricks MLflowã«è¨˜éŒ²ã—ã¾ã—ãŸ")
    
    # æ¯”è¼ƒã‚µãƒãƒªãƒ¼ã‚’è¨˜éŒ²
    with mlflow.start_run(run_name="large_tsp_comparison_summary"):
        mlflow.log_param("experiment_type", "Large_TSP_Comparison")
        mlflow.log_param("num_instances", len(tsp_instances))
        mlflow.log_param("instance_sizes", str(tsp_sizes))
        mlflow.log_param("max_instance_size", max(tsp_sizes))
        
        # é›†è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
        ortools_wins = sum(1 for data in comparison_data if data['winner'] == 'OR-Tools')
        mip_wins = sum(1 for data in comparison_data if data['winner'] == 'MIP')
        ties = sum(1 for data in comparison_data if data['winner'] == 'Tie')
        
        mlflow.log_metric("ortools_wins", ortools_wins)
        mlflow.log_metric("mip_wins", mip_wins)
        mlflow.log_metric("ties", ties)
        
        # å¹³å‡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        avg_ortools_time = np.mean([d['ortools_time'] for d in comparison_data])
        avg_mip_time = np.mean([d['mip_time'] for d in comparison_data])
        mlflow.log_metric("avg_ortools_time", avg_ortools_time)
        mlflow.log_metric("avg_mip_time", avg_mip_time)
        
        # æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿
        summary_file = "large_comparison_summary.json"
        with open(summary_file, 'w') as f:
            json.dump(comparison_data, f, indent=2)
        mlflow.log_artifact(summary_file)
        os.remove(summary_file)
        
        # ã™ã¹ã¦ã®å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦è¨˜éŒ²
        for viz_file in visualization_files:
            if os.path.exists(viz_file):
                mlflow.log_artifact(viz_file)
    
    print("  æ¯”è¼ƒã‚µãƒãƒªãƒ¼ã¨å¯è¦–åŒ–ã‚’Databricks MLflowã«è¨˜éŒ²ã—ã¾ã—ãŸ")
    
    # 8. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    for viz_file in visualization_files:
        if os.path.exists(viz_file):
            os.remove(viz_file)
    
    # 9. çµæœã®è¡¨ç¤º
    print("\n" + "="*80)
    print("å¤§è¦æ¨¡TSP Solver Comparison Results")
    print("="*80)
    print(f"{'Instance':<10} {'OR-Tools Cost':<15} {'MIP Cost':<15} {'OR-Tools Time':<15} {'MIP Time':<15} {'Winner':<10}")
    print("-"*80)
    
    for data in comparison_data:
        ot_cost = data['ortools_cost']
        mp_cost = data['mip_cost']
        ot_cost_str = f"{ot_cost:.1f}" if ot_cost != float('inf') else "N/A"
        mp_cost_str = f"{mp_cost:.1f}" if mp_cost != float('inf') else "N/A"
        
        print(f"{data['instance']:<10} {ot_cost_str:<15} {mp_cost_str:<15} {data['ortools_time']:<15.2f} {data['mip_time']:<15.2f} {data['winner']:<10}")
    
    print(f"\nOR-Toolså‹åˆ©: {ortools_wins}")
    print(f"MIPå‹åˆ©: {mip_wins}")
    print(f"å¼•ãåˆ†ã‘: {ties}")
    
    print(f"\nOR-Toolså¹³å‡æ™‚é–“: {avg_ortools_time:.2f}ç§’")
    print(f"MIPå¹³å‡æ™‚é–“: {avg_mip_time:.2f}ç§’")
    
    print("\nâœ… å¤§è¦æ¨¡TSPå®Ÿé¨“ãŒå®Œäº†ã—ã€Databricks MLflowã«è¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼")
    print("ğŸ“Š Databricksã§å®Ÿé¨“çµæœã‚’ç¢ºèªã§ãã¾ã™: /Shared/data_science/z_ogai/tsp-large-experiments")
    print("ğŸ¨ ãƒ«ãƒ¼ãƒˆå¯è¦–åŒ–ã‚‚ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")


if __name__ == "__main__":
    main()